{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install pdfminer.six\n",
        "%pip install numpy\n",
        "%pip install pandas\n",
        "%pip install pytz\n",
        "%pip install tika\n",
        "%pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "%pip install opencv-python\n",
        "%pip install pymupdf\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kC824XzBULaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import json\n",
        "import re\n",
        "from itertools import chain\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytz \n",
        "import spacy\n",
        "import fitz  #pymudf\n",
        "import cv2 #opencv-python\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load spacy pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Timezone\n",
        "timezone = pytz.timezone('Asia/Jakarta')\n",
        "\n",
        "# Regex / Reference List\n",
        "UNIVERSITIES_REF = '/content/drive/MyDrive/Project/!Playground/world-universities.csv'\n",
        "MAJOR_REF = '/content/drive/MyDrive/Project/!Playground/majors-list.csv'\n",
        "SKILL_REF = '/content/drive/MyDrive/Project/!Playground/skills.csv'\n",
        "DEGREE_REF = ['s3','doctoral','doktor','s2','master','magister','s1','bachelor','sarjana','vokasi']\n",
        "OCCUPATION_REF = '/content/drive/MyDrive/Project/!Playground/occupation.csv'\n",
        "BIRTHPLACE_REF = '/content/drive/MyDrive/Project/!Playground/birthplace.csv'\n",
        "PHONE_REG = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
        "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
        "WEB_REG = re.compile(r'(https?://\\S+)')\n",
        "\n",
        "# Function\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    document  = fitz.open(pdf_path)\n",
        "    text = []\n",
        "    for page in range(document.page_count):\n",
        "        text.append(document.get_page_text(page))\n",
        "    return ' '.join(text)\n",
        "\n",
        "def extract_phone_number(text):\n",
        "    text = text.replace(' ','')\n",
        "    phone = set(re.findall(PHONE_REG, text))\n",
        "    if phone:\n",
        "        for number in phone:\n",
        "            if len(number) >= 10 and len(number) < 16 and '.' not in number:\n",
        "                return number\n",
        "    \n",
        "def extract_emails(text):\n",
        "    email = re.findall(EMAIL_REG, text)\n",
        "    if email:\n",
        "        mail = email\n",
        "        return mail[0]\n",
        "\n",
        "def extract_website(text):\n",
        "    text = text = re.sub(r'[()]', '', text)\n",
        "    web = re.findall(WEB_REG, text)\n",
        "    if web:\n",
        "        return web\n",
        "\n",
        "def extract_college(text):\n",
        "    file = UNIVERSITIES_REF\n",
        "    df = pd.read_csv(file, header=None)\n",
        "    universities = [i.lower() for i in df[1]]\n",
        "    college_name = []\n",
        "\n",
        "    for i in range(len(text)):\n",
        "        for univ in universities:\n",
        "            if univ in text[i]:\n",
        "                if univ not in college_name:\n",
        "                    college_name.append(univ)\n",
        "\n",
        "    if len(college_name) == 0:\n",
        "        for i in range(len(text)):\n",
        "            if text[i].startswith('university'):\n",
        "                if text[i] not in college_name:\n",
        "                    college_name.append(text[i].strip())  \n",
        "\n",
        "    if college_name:\n",
        "      return college_name\n",
        "\n",
        "def extract_major(text, univ):\n",
        "    file = MAJOR_REF\n",
        "    df = pd.read_csv(file)\n",
        "    major_specific = [x for x in df['SPECIFIC'].str.lower().values if x is not np.nan]\n",
        "    major_general = [x for x in df['GENERAL'].str.lower().values if x is not np.nan]\n",
        "    major = set([])\n",
        "    for i in range(len(text)):\n",
        "        if univ in text[i]:\n",
        "            try:\n",
        "                out = text[i-2] + ' ' + text[i-1] + ' ' + text[i] + ' ' + text[i+1] + ' ' + text[i+2]\n",
        "            except:\n",
        "                out = text[i-2] + ' ' + text[i-1] + ' ' + text[i]\n",
        "            for row in major_specific:\n",
        "                    if row in out:\n",
        "                        major.add(row)\n",
        "            if len(major) == 0:\n",
        "                for row in major_general:\n",
        "                    if row in out:\n",
        "                        major.add(row)\n",
        "            if major:\n",
        "                return ' '.join(major)\n",
        "\n",
        "def extract_degree(text, univ):\n",
        "    for i in range(len(text)):\n",
        "        if univ in text[i]:\n",
        "            try:\n",
        "                out = text[i-2] + ' ' + text[i-1] + ' ' + text[i] + ' ' + text[i+1] + ' ' + text[i+2]\n",
        "            except:\n",
        "                out = text[i-2] + ' ' + text[i-1] + ' ' + text[i]\n",
        "            for degree in DEGREE_REF:\n",
        "                if degree in out:\n",
        "                    return degree\n",
        "\n",
        "def extract_education2(text):\n",
        "    filter = ['develop', 'create', 'make', 'collaborate']\n",
        "    text = [s for s in text.split('\\n') if not any(x in s for x in filter)]\n",
        "\n",
        "    uni = extract_college(text)\n",
        "    edu = []\n",
        "    deg = []\n",
        "  \n",
        "    for degree in DEGREE_REF:\n",
        "        for i in range(len(text)):\n",
        "            if text[i].startswith(degree):\n",
        "                deg.append(degree)\n",
        "    \n",
        "    if uni:\n",
        "        if len(uni) == 1 and len(deg) > 1:\n",
        "            for i in range(len(deg)):\n",
        "                dct = {}\n",
        "                dct['college'] = uni[0] \n",
        "                dct['major'] = extract_major(text, deg[i])\n",
        "                dct['degree'] = extract_degree(text, uni[0])\n",
        "                edu.append(dct)\n",
        "            if len(edu) == 3:\n",
        "                edu[1]['degree'] = 'master'\n",
        "                edu[2]['degree'] = 'bachelor'\n",
        "            elif len(edu) == 2:\n",
        "                edu[1]['degree'] = 'bachelor'\n",
        "        else:\n",
        "            for item in uni:\n",
        "                dct = {}\n",
        "                dct['college'] = item \n",
        "                dct['major'] = extract_major(text, item)\n",
        "                dct['degree'] = extract_degree(text, item)\n",
        "                edu.append(dct)\n",
        "        return edu\n",
        "\n",
        "def extract_skills(text):\n",
        "    nlp_text = nlp(text)\n",
        "    noun_chunks = nlp_text.noun_chunks\n",
        "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "    df = pd.read_csv(SKILL_REF, header=None) \n",
        "    skills = df[0].values\n",
        "    skillset = []\n",
        "    \n",
        "    for token in tokens:\n",
        "        if token.lower() in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    for token in noun_chunks:\n",
        "        token = token.text.lower().strip()\n",
        "        if token in skills:\n",
        "            skillset.append(token)\n",
        "   \n",
        "    skillset = list(set(skillset))\n",
        "    return sorted(skillset)\n",
        "\n",
        "def extract_estimated_work_year_experience(text, job):\n",
        "    text = [x.strip() for x in text.encode(\"ascii\", \"ignore\").decode().split('\\n') if x and x != ' ']\n",
        "    temp = []\n",
        "\n",
        "    for j in job:\n",
        "        for i in range(len(text)):\n",
        "            if j in text[i]:\n",
        "                try:\n",
        "                    out = text[i-1] + ' ' + text[i] + ' ' + text[i+1]\n",
        "                except:\n",
        "                    out = text[i-1] + ' ' + text[i]\n",
        "                temp.append(out)\n",
        "    \n",
        "    nlp_text = nlp(' '.join(temp))\n",
        "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "    digit = list(set([x for x in tokens if x.isdigit()]))\n",
        "    \n",
        "    if digit:\n",
        "        digit.append(str(datetime.today().year))\n",
        "        digit = [x for x in digit if len(x)>=4]\n",
        "        year = [int(x) for x in digit]\n",
        "        year = [x for x in year if x <= datetime.today().year]\n",
        "        return str(max(year) - min(year))\n",
        "\n",
        "def extract_occupation(text):\n",
        "    filter = ['regression','degree','major','improve','sometimes','create','creating', ' to ','progress']\n",
        "    text = [x.encode(\"ascii\", \"ignore\").decode() for x in text.split('\\n') if not any(s in x for s in filter)]\n",
        "    df = pd.read_csv(OCCUPATION_REF)\n",
        "    joblist_specific = [x for x in df['specific'].str.lower().values if x is not np.nan]\n",
        "    joblist_general = [x for x in df['general'].str.lower().values if x is not np.nan]\n",
        "    occupation = set([])\n",
        "\n",
        "    for i in range(len(text)):\n",
        "        temp = re.sub(r'[^\\w\\s]', '',text[i]).strip()\n",
        "        temp = re.sub(r' +', ' ',temp)\n",
        "        for job in joblist_specific:\n",
        "            if job in temp:\n",
        "                occupation.add(job)\n",
        "        for job in joblist_general:\n",
        "            if job in temp and len(temp.split())<8:\n",
        "                occupation.add(temp)\n",
        "  \n",
        "    if occupation:\n",
        "        return list(occupation)\n",
        "\n",
        "def pix2np(pix):\n",
        "    im = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)\n",
        "    im = np.ascontiguousarray(im[..., [2, 1, 0]])  \n",
        "    return im\n",
        "\n",
        "def extract_photo(pdf, folderpath):\n",
        "    name = os.path.basename(pdf)\n",
        "    filepath = os.path.join(folderpath, name + '.jpg')\n",
        "\n",
        "    doc = fitz.open(pdf) \n",
        "    page = doc.load_page(0)\n",
        "    pix = page.get_pixmap(matrix=fitz.Matrix(3, 3))\n",
        "    img = pix2np(pix)\n",
        "  \n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml')\n",
        "    faces = face_cascade.detectMultiScale(img, 1.1, 4)\n",
        "  \n",
        "    i = 0\n",
        "    while i == 0:\n",
        "        i = i + 1\n",
        "        for (x, y, w, h) in faces:\n",
        "            #cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "            faces = img[y - 50 : y + h + 100, x - 50 : x + w + 50]\n",
        "            #cv2.imshow(faces)\n",
        "            #cv2_imshow(faces)\n",
        "            cv2.imwrite(filepath, faces)\n",
        "            return filepath\n",
        "\n",
        "# Main\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    # Folder cv path\n",
        "    path = '/content/drive/MyDrive/Project/!Playground/CV'\n",
        "\n",
        "    # Folder dump face\n",
        "    FACE_PATH = '/content/drive/MyDrive/Project/!Playground/Face/'\n",
        "\n",
        "    # Iterate through all file\n",
        "    cv = []\n",
        "    for file in os.listdir(path):\n",
        "        file_path = f\"{path}/{file}\"\n",
        "        cv.append(file_path)\n",
        "\n",
        "    # Input cv\n",
        "    filepath = cv[5]\n",
        "    text = extract_text_from_pdf(filepath)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Extract information\n",
        "    created = str(datetime.now(timezone))\n",
        "    phone_number = extract_phone_number(text)\n",
        "    email = extract_emails(text)\n",
        "    website = extract_website(text)\n",
        "    education = extract_education2(text)\n",
        "    skills = extract_skills(text)\n",
        "    occupation = extract_occupation(text)\n",
        "    yearworkexp = extract_estimated_work_year_experience(text, occupation)\n",
        "    photo = extract_photo(filepath, FACE_PATH)\n",
        "\n",
        "    # Create JSON\n",
        "    jsons = {\n",
        "        'filepath': filepath,\n",
        "        'created': created,\n",
        "        'face_photo' : photo,\n",
        "        'phone_number': phone_number,\n",
        "        'email': email,\n",
        "        'website' : website,\n",
        "        'estimated_working_year_experience' : yearworkexp,\n",
        "        'work_experience': occupation,\n",
        "        'education':education,\n",
        "        'skills': skills,\n",
        "        }\n",
        "\n",
        "    print(json.dumps(jsons, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIaq1f2vodmE",
        "outputId": "69d3a526-1694-462b-c0ac-da2955ba2a04"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"filepath\": \"/content/drive/MyDrive/Project/!Playground/CV/Yudho Prakoso-resume.pdf\",\n",
            "  \"created\": \"2022-09-20 19:44:02.890281+07:00\",\n",
            "  \"face_photo\": \"/content/drive/MyDrive/Project/!Playground/Face/Yudho Prakoso-resume.pdf.jpg\",\n",
            "  \"phone_number\": \"82214886517\",\n",
            "  \"email\": \"yudopr10@gmail.com\",\n",
            "  \"website\": [\n",
            "    \"https://www.linkedin.com/in/yudho-prakoso-a057a323b/\",\n",
            "    \"https://freecodecamp.org/certification/\",\n",
            "    \"https://doi.org/10.1145/3239283.3239297\"\n",
            "  ],\n",
            "  \"estimated_working_year_experience\": \"7\",\n",
            "  \"work_experience\": [\n",
            "    \"mathematics tutor\",\n",
            "    \"content ops lead\",\n",
            "    \"mathematics teacher\"\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"college\": \"universitas indonesia\",\n",
            "      \"major\": \"mathematics\",\n",
            "      \"degree\": \"bachelor\"\n",
            "    }\n",
            "  ],\n",
            "  \"skills\": [\n",
            "    \"analysis\",\n",
            "    \"bigquery\",\n",
            "    \"c\",\n",
            "    \"data science\",\n",
            "    \"etl\",\n",
            "    \"excel\",\n",
            "    \"google sheets\",\n",
            "    \"information technology\",\n",
            "    \"mathematics\",\n",
            "    \"mysql\",\n",
            "    \"pentaho\",\n",
            "    \"plan\",\n",
            "    \"postgresql\",\n",
            "    \"project management\",\n",
            "    \"python\",\n",
            "    \"sql\",\n",
            "    \"sql server\",\n",
            "    \"tableau\",\n",
            "    \"teaching\",\n",
            "    \"ui\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}