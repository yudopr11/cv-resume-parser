{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfminer.six\n",
        "!pip install numpy\n",
        "!pip install tika\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install opencv-python\n",
        "!pip install pymupdf\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kC824XzBULaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "from dateutil.parser import parse\n",
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytz \n",
        "from pdfminer.high_level import extract_text\n",
        "from tika import parser  \n",
        "import spacy\n",
        "import fitz  \n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load spacy pre-trained model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Timezone\n",
        "timezone = pytz.timezone('Asia/Jakarta')\n",
        "\n",
        "# Regex / Reference List\n",
        "UNIVERSITIES_REF = '/content/drive/MyDrive/Project/!Playground/world-universities.csv'\n",
        "MAJOR_REF = '/content/drive/MyDrive/Project/!Playground/majors-list.csv'\n",
        "SKILL_REF = '/content/drive/MyDrive/Project/!Playground/skills.csv'\n",
        "DEGREE_REF = ['s1','s2','s3','vokasi','bachelor','master','doctoral','sarjana','magister','doktor']\n",
        "OCCUPATION_REF = '/content/drive/MyDrive/Project/!Playground/occupation.csv'\n",
        "PHONE_REG = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
        "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
        "WEB_REG = re.compile(r'(https?://\\S+)')\n",
        "\n",
        "# Function\n",
        "def extract_text_from_pdf(pdf_path, option):\n",
        "    if option == 'tika':\n",
        "      return parser.from_file(pdf_path)['content']\n",
        "    elif option == 'pdfminer':\n",
        "      return extract_text(pdf_path)\n",
        "\n",
        "def extract_phone_number(text):\n",
        "    phone = re.findall(PHONE_REG, text)\n",
        "    if phone:\n",
        "        number = phone[0]\n",
        "        if text.find(number) >= 0 and len(number) < 16:\n",
        "            return number\n",
        "    \n",
        "def extract_emails(text):\n",
        "    email = re.findall(EMAIL_REG, text)\n",
        "    if email:\n",
        "        mail = email\n",
        "        return mail[0]\n",
        "\n",
        "def extract_website(text):\n",
        "    text = text = re.sub(r'[()]', '', text)\n",
        "    web = re.findall(WEB_REG, text)\n",
        "    if web:\n",
        "        return web\n",
        "\n",
        "def extract_college(text):\n",
        "    file = UNIVERSITIES_REF\n",
        "    df = pd.read_csv(file, header=None)\n",
        "    universities = [i.lower() for i in df[1]]\n",
        "    college_name = []\n",
        "    listex = universities\n",
        "    listsearch = [text]\n",
        "\n",
        "    for i in range(len(listex)):\n",
        "        for j in range(len(listsearch)): \n",
        "            if re.findall(listex[i], re.sub(' +', ' ', listsearch[j])):    \n",
        "                college_name.append(listex[i])\n",
        "    if college_name:    \n",
        "        return college_name\n",
        "\n",
        "def extract_major(text, univ):\n",
        "    file = MAJOR_REF\n",
        "    df = pd.read_csv(file, header=None)\n",
        "    major = df[0].str.lower().values\n",
        "    text = [x for x in text.split('\\n') if x and x != ' ']\n",
        "    for i in range(len(text)):\n",
        "        if univ in text[i]:\n",
        "            try:\n",
        "                out = text[i-1]+text[i]+text[i+1]\n",
        "                for row in major:\n",
        "                    if row in out:\n",
        "                        return row\n",
        "            except:\n",
        "                out = text[i-1]+text[i]\n",
        "                for row in major:\n",
        "                    if row in out:\n",
        "                        return row\n",
        "\n",
        "def extract_degree(text, univ):\n",
        "    text = [x for x in text.split('\\n') if x and x != ' ']\n",
        "    for i in range(len(text)):\n",
        "        if univ in text[i]:\n",
        "            try:\n",
        "                out = text[i-1]+text[i]+text[i+1]\n",
        "                for degree in DEGREE_REF:\n",
        "                    if degree in out:\n",
        "                        return degree\n",
        "            except:\n",
        "                out = text[i-1]+text[i]\n",
        "                for degree in DEGREE_REF:\n",
        "                    if degree in out:\n",
        "                        return degree\n",
        "\n",
        "def extract_education(text):\n",
        "    text = text[text.index('education'):]\n",
        "    uni = extract_college(text)\n",
        "    edu = []\n",
        "    if uni:\n",
        "        for item in uni:\n",
        "            dct = {}\n",
        "            dct['college'] = item \n",
        "            dct['major'] = extract_major(text, item)\n",
        "            dct['degree'] = extract_degree(text, item)\n",
        "            edu.append(dct)\n",
        "        return edu\n",
        "\n",
        "# EXPERIMENTAL take master/doctoral in same college\n",
        "def extract_education2(text):\n",
        "    uni = extract_college(text)\n",
        "    edu = []\n",
        "    deg = []\n",
        "  \n",
        "    for degree in DEGREE_REF:\n",
        "        if degree in text:\n",
        "            deg.append(degree)\n",
        " \n",
        "    if uni:\n",
        "        if len(uni) == 1 and len(deg) > 1:\n",
        "            for i in range(len(deg)):\n",
        "                dct = {}\n",
        "                dct['college'] = uni[0] \n",
        "                dct['major'] = extract_major(text, uni[0])\n",
        "                dct['degree'] = extract_degree(text, uni[0])\n",
        "                edu.append(dct)\n",
        "            if len(edu) == 3:\n",
        "                edu[1]['degree'] = 'master'\n",
        "                edu[2]['degree'] = 'bachelor'\n",
        "            elif len(edu) == 2:\n",
        "                edu[1]['degree'] = 'bachelor'\n",
        "        else:\n",
        "            for item in uni:\n",
        "                dct = {}\n",
        "                dct['college'] = item \n",
        "                dct['major'] = extract_major(text, item)\n",
        "                dct['degree'] = extract_degree(text, item)\n",
        "                edu.append(dct)\n",
        "        return edu\n",
        "\n",
        "def extract_skills(text):\n",
        "    nlp_text = nlp(text)\n",
        "    noun_chunks = nlp_text.noun_chunks\n",
        "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
        "    df = pd.read_csv(SKILL_REF, header=None) \n",
        "    skills = df[0].values\n",
        "    skillset = []\n",
        "    \n",
        "    for token in tokens:\n",
        "        if token.lower() in skills:\n",
        "            skillset.append(token)\n",
        "    \n",
        "    for token in noun_chunks:\n",
        "        token = token.text.lower().strip()\n",
        "        if token in skills:\n",
        "            skillset.append(token)\n",
        "   \n",
        "    skillset = list(set(skillset))\n",
        "    return skillset \n",
        "\n",
        "def extract_estimated_work_year_experience(text):\n",
        "    tex = [x for x in text.split('\\n') if x and x != ' ']\n",
        "\n",
        "    indices = []\n",
        "    for i in range(len(tex)):\n",
        "        line = tex[i]\n",
        "        if 'dob' in line or 'birth' in line or 'born' in line:\n",
        "            indices.append(i)\n",
        "\n",
        "    tex = [i for j, i in enumerate(tex) if j not in indices]\n",
        "    text = nlp(' '.join(tex))\n",
        "    tokens = [token.text for token in text if not token.is_stop]\n",
        "    digit = list(set([x for x in tokens if x.isdigit() or x == 'present']))\n",
        "\n",
        "    if 'present' in digit:\n",
        "        digit[digit.index('present')] = str(datetime.today().year)\n",
        "  \n",
        "    digit = [x for x in digit if len(x)>=4]\n",
        "    year = [int(x) for x in digit]\n",
        "    year = [x for x in year if x <= datetime.today().year]\n",
        "  \n",
        "    if year:\n",
        "        return max(year) - min(year) - 4\n",
        "\n",
        "def extract_occupation(text):\n",
        "    text = ' '.join([x for x in text.split('\\n') if x and x != ' '])\n",
        "    df = pd.read_csv(OCCUPATION_REF, header=None)\n",
        "    joblist = df[0].str.lower().values\n",
        "    occupation = []\n",
        "\n",
        "    for job in joblist:\n",
        "        if (' '+ job + ' ') in text:\n",
        "            occupation.append(job)\n",
        "  \n",
        "    if occupation:\n",
        "        return occupation\n",
        "\n",
        "def pix2np(pix):\n",
        "    im = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)\n",
        "    im = np.ascontiguousarray(im[..., [2, 1, 0]])  \n",
        "    return im\n",
        "\n",
        "def extract_photo(pdf, folderpath):\n",
        "    name = os.path.basename(pdf)\n",
        "    filepath = os.path.join(folderpath, name + '.jpg')\n",
        "\n",
        "    doc = fitz.open(pdf) \n",
        "    page = doc.load_page(0)\n",
        "    pix = page.get_pixmap(matrix=fitz.Matrix(3, 3))\n",
        "    img = pix2np(pix)\n",
        "  \n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml')\n",
        "    faces = face_cascade.detectMultiScale(img, 1.1, 4)\n",
        "  \n",
        "    i = 0\n",
        "    while i == 0:\n",
        "        i = i + 1\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "            faces = img[y:y + h, x:x + w]\n",
        "            #cv2.imshow(faces)\n",
        "            #cv2_imshow(faces)\n",
        "            cv2.imwrite(filepath, faces)\n",
        "            return filepath\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    # Folder cv path\n",
        "    path = '/content/drive/MyDrive/Project/!Playground/CV'\n",
        "\n",
        "    # Folder dump face\n",
        "    FACE_PATH = '/content/drive/MyDrive/Project/!Playground/Face/'\n",
        "\n",
        "    # Iterate through all file\n",
        "    cv = []\n",
        "    for file in os.listdir(path):\n",
        "        file_path = f\"{path}/{file}\"\n",
        "        cv.append(file_path)\n",
        "\n",
        "    # Input cv\n",
        "    filepath = cv[0]\n",
        "    text = extract_text_from_pdf(filepath, 'tika') #apache tika or pdfminer\n",
        "    text = text.lower()\n",
        "\n",
        "    # Extract information\n",
        "    created = datetime.now(timezone)\n",
        "    phone_number = extract_phone_number(text)\n",
        "    email = extract_emails(text)\n",
        "    website = extract_website(text)\n",
        "    education = extract_education2(text)\n",
        "    skills = extract_skills(text)\n",
        "    yearworkexp = extract_estimated_work_year_experience(text)\n",
        "    occupation = extract_occupation(text)\n",
        "    photo = extract_photo(filepath, FACE_PATH)\n",
        "\n",
        "    # Create JSON\n",
        "    jsons = {\n",
        "        'filepath': filepath,\n",
        "        'created': str(created),\n",
        "        'photo' : photo,\n",
        "        'phone_number': phone_number,\n",
        "        'email': email,\n",
        "        'estimated_working_year_experience' : str(yearworkexp),\n",
        "        'working_experience': occupation,\n",
        "        'website' : website,\n",
        "        'skills': skills,\n",
        "        'education':education\n",
        "        }\n",
        "\n",
        "    print(json.dumps(jsons, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIaq1f2vodmE",
        "outputId": "3d5a6f2a-d90c-4506-f203-6fbb9932046e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"filepath\": \"/content/drive/MyDrive/Project/!Playground/CV/Yudho Prakoso-resume.pdf\",\n",
            "  \"created\": \"2022-09-13 21:38:38.257215+07:00\",\n",
            "  \"photo\": \"/content/drive/MyDrive/Project/!Playground/Face/Yudho Prakoso-resume.pdf.jpg\",\n",
            "  \"phone_number\": \"82213886517\",\n",
            "  \"email\": \"yudopr10@gmail.com\",\n",
            "  \"estimated_working_year_experience\": \"4\",\n",
            "  \"working_experience\": [\n",
            "    \"lead\",\n",
            "    \"tutor\"\n",
            "  ],\n",
            "  \"website\": [\n",
            "    \"https://www.linkedin.com/in/yudho-prakoso-a057a323b/\",\n",
            "    \"https://freecodecamp.org/certification/\",\n",
            "    \"https://doi.org/10.1145/3239283.3239297\"\n",
            "  ],\n",
            "  \"skills\": [\n",
            "    \"data science\",\n",
            "    \"excel\",\n",
            "    \"sql server\",\n",
            "    \"ui\",\n",
            "    \"analysis\",\n",
            "    \"pentaho\",\n",
            "    \"python\",\n",
            "    \"teaching\",\n",
            "    \"c\",\n",
            "    \"information technology\",\n",
            "    \"postgresql\",\n",
            "    \"project management\",\n",
            "    \"sql\",\n",
            "    \"mysql\",\n",
            "    \"mathematics\",\n",
            "    \"etl\",\n",
            "    \"plan\",\n",
            "    \"tableau\",\n",
            "    \"google sheets\",\n",
            "    \"bigquery\"\n",
            "  ],\n",
            "  \"education\": [\n",
            "    {\n",
            "      \"college\": \"universitas indonesia\",\n",
            "      \"major\": \"mathematics\",\n",
            "      \"degree\": \"bachelor\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}